{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to PyTypes \u00b6 \u03bb poetry run python main.py --help Usage: main.py [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit. Commands: confgen Generate pytypes.toml evaluate Evaluate given original and traced repository fetch Download repositories and apply tracing decorators typegen Generate type hinted files using trace data Workflow \u00b6 Fetching: poetry run python main.py fetch --help Confgen: poetry run python main.py confgen --help Tracing Typegen: poetry run python main.py typegen --help Evaluating: poetry run python main.py evaluate --help Miscellaneous \u00b6 Resolver Config Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-pytypes","text":"\u03bb poetry run python main.py --help Usage: main.py [OPTIONS] COMMAND [ARGS]... Options: --help Show this message and exit. Commands: confgen Generate pytypes.toml evaluate Evaluate given original and traced repository fetch Download repositories and apply tracing decorators typegen Generate type hinted files using trace data","title":"Welcome to PyTypes"},{"location":"#workflow","text":"Fetching: poetry run python main.py fetch --help Confgen: poetry run python main.py confgen --help Tracing Typegen: poetry run python main.py typegen --help Evaluating: poetry run python main.py evaluate --help","title":"Workflow"},{"location":"#miscellaneous","text":"Resolver Config","title":"Miscellaneous"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"about/","text":"Project Motivation \u00b6","title":"About"},{"location":"about/#project-motivation","text":"","title":"Project Motivation"},{"location":"api/common/","text":"Resolver dataclass \u00b6 Bidirectional lookup of types and modules Parameters: Name Type Description Default proj_path pathlib . Path Path to root directory containing the project's types required stdlib_path pathlib . Path Path to standard library's directory of the Python binary, containing stdlib types required venv_path pathlib . Path Path to project's virtual environment's directory containing third-party deps required Raises: Type Description ValueError If any of the three specified paths is not a directory type_lookup ( module_name , type_name ) \u00b6 Create a type from a module path and qualified type name. Fails if the given paths lies outside of the module Parameters: Name Type Description Default module_name str | None | pd . _libs . missing . NAType The module of the type e.g. pathlib required type_name str The fully qualified name of the type, e.g. Path required Returns: Type Description type | None The requested type if found, e.g. pathlib.Path, else None get_module_and_name ( ty ) \u00b6 Retrieve module path and qualified type name from a type. Fails if the type lies outside of the three paths specified in the constructor. Parameters: Name Type Description Default ty type Any given type whose defining file is relative to the specified paths required Returns: Type Description tuple [ str | None, str ] | None a pair of (module name, type name) if successful, where module_name is None is the type is a builtin TraceDataCategory \u00b6 Bases: enum . IntEnum The trace data category. Used by the tracer to mark the semantic of each row LOCAL_VARIABLE = 1 class-attribute \u00b6 Signifies a local variable in the trace data FUNCTION_PARAMETER = 2 class-attribute \u00b6 Indicates that the traced instance is a function parameter FUNCTION_RETURN = 3 class-attribute \u00b6 Marks the return type of a callable CLASS_MEMBER = 4 class-attribute \u00b6 Indicates a class member / attribute GLOBAL_VARIABLE = 5 class-attribute \u00b6 Signifies a global variable INVALID = 0 class-attribute \u00b6 Denotes otherwise unknown category. Currently unused DataFileCollector \u00b6 Bases: ABC Collects data files in a given path. __init__ ( file_pattern ) \u00b6 Creates an instance of DataFileCollector. Parameters: Name Type Description Default file_pattern str The file pattern of the data files to be collected. required collect_data ( path , include_also_files_in_subdirectories = True ) \u00b6 Collects the data in a given path. Parameters: Name Type Description Default path pathlib . Path The path of the folder containing the files. required include_also_files_in_subdirectories bool Whether the data files in the subfolders should also be collected. True","title":"Common"},{"location":"api/common/#common.resolver.Resolver","text":"Bidirectional lookup of types and modules Parameters: Name Type Description Default proj_path pathlib . Path Path to root directory containing the project's types required stdlib_path pathlib . Path Path to standard library's directory of the Python binary, containing stdlib types required venv_path pathlib . Path Path to project's virtual environment's directory containing third-party deps required Raises: Type Description ValueError If any of the three specified paths is not a directory","title":"Resolver"},{"location":"api/common/#common.resolver.Resolver.type_lookup","text":"Create a type from a module path and qualified type name. Fails if the given paths lies outside of the module Parameters: Name Type Description Default module_name str | None | pd . _libs . missing . NAType The module of the type e.g. pathlib required type_name str The fully qualified name of the type, e.g. Path required Returns: Type Description type | None The requested type if found, e.g. pathlib.Path, else None","title":"type_lookup()"},{"location":"api/common/#common.resolver.Resolver.get_module_and_name","text":"Retrieve module path and qualified type name from a type. Fails if the type lies outside of the three paths specified in the constructor. Parameters: Name Type Description Default ty type Any given type whose defining file is relative to the specified paths required Returns: Type Description tuple [ str | None, str ] | None a pair of (module name, type name) if successful, where module_name is None is the type is a builtin","title":"get_module_and_name()"},{"location":"api/common/#common.trace_data_category.TraceDataCategory","text":"Bases: enum . IntEnum The trace data category. Used by the tracer to mark the semantic of each row","title":"TraceDataCategory"},{"location":"api/common/#common.trace_data_category.TraceDataCategory.LOCAL_VARIABLE","text":"Signifies a local variable in the trace data","title":"LOCAL_VARIABLE"},{"location":"api/common/#common.trace_data_category.TraceDataCategory.FUNCTION_PARAMETER","text":"Indicates that the traced instance is a function parameter","title":"FUNCTION_PARAMETER"},{"location":"api/common/#common.trace_data_category.TraceDataCategory.FUNCTION_RETURN","text":"Marks the return type of a callable","title":"FUNCTION_RETURN"},{"location":"api/common/#common.trace_data_category.TraceDataCategory.CLASS_MEMBER","text":"Indicates a class member / attribute","title":"CLASS_MEMBER"},{"location":"api/common/#common.trace_data_category.TraceDataCategory.GLOBAL_VARIABLE","text":"Signifies a global variable","title":"GLOBAL_VARIABLE"},{"location":"api/common/#common.trace_data_category.TraceDataCategory.INVALID","text":"Denotes otherwise unknown category. Currently unused","title":"INVALID"},{"location":"api/common/#common.data_file_collector.DataFileCollector","text":"Bases: ABC Collects data files in a given path.","title":"DataFileCollector"},{"location":"api/common/#common.data_file_collector.DataFileCollector.__init__","text":"Creates an instance of DataFileCollector. Parameters: Name Type Description Default file_pattern str The file pattern of the data files to be collected. required","title":"__init__()"},{"location":"api/common/#common.data_file_collector.DataFileCollector.collect_data","text":"Collects the data in a given path. Parameters: Name Type Description Default path pathlib . Path The path of the folder containing the files. required include_also_files_in_subdirectories bool Whether the data files in the subfolders should also be collected. True","title":"collect_data()"},{"location":"api/evaluation/","text":"FileTypeHintsCollector \u00b6 Collects the type hints of multiple .py files. __init__ () \u00b6 Creates an instance of FileTypeHintsCollector. collect_data_from_file ( root , filename ) \u00b6 Collects the typehint data from a file. Parameters: Name Type Description Default root pathlib . Path The root folder path of the file. required filename str The file name. required collect_data_from_files ( root , filenames ) \u00b6 Collects the typehint data from multiple files. Parameters: Name Type Description Default root pathlib . Path The root folder path of the files. required filenames list [ str ] The file names. required collect_data_from_folder ( root , folder , include_also_files_in_subdirectories = True ) \u00b6 Collects the typehint data from the files in the folder. Parameters: Name Type Description Default root pathlib . Path The root folder path. required folder pathlib . Path The path of the folder containing the files. required include_also_files_in_subdirectories bool Whether the type hints in the files in the subfolders should also be collected. True collect_data ( root , file_paths ) \u00b6 Collects the typehint data from the files in the provided file paths. Parameters: Name Type Description Default root pathlib . Path The root folder path. required file_paths Iterable [ pathlib . Path ] The file paths. required MetricDataCalculator \u00b6 Calculates the metric data. __init__ () \u00b6 Creates an instance of MetricDataCalculator. add_filename_mapping ( original_filename , generated_filename ) \u00b6 Adds a mapping: generated file name -> original file name. Used to determine which generated file corresponds to which original file. calculate the metric data. Parameters: Name Type Description Default original_filename str The original file name. required generated_filename str The generated file name. required get_metric_data ( original_type_hint_data , generated_type_hint_data ) \u00b6 Calculates the metric data containing the correctness & completeness. Parameters: Name Type Description Default original_type_hint_data pd . DataFrame The original typehint data. required generated_type_hint_data pd . DataFrame The generated typehint data. required get_total_completeness_and_correctness ( metric_data ) \u00b6 Gets the total completeness & correctness of a given metric data. Parameters: Name Type Description Default metric_data pd . DataFrame The metric data. required Returns: Type Description tuple [ float , float ] The total completeness & correctness. normalize_type ( type_hint ) \u00b6 Gets the type union written as a type union using only | . Normalizes typing.Union, typing.Optional and | unions. Does also normalize inner type unions, for example: list[int | str]. Parameters: Name Type Description Default type_hint str The type hint name to normalize. required Returns: Type Description str the normalized type hint name. PerformanceDataFileCollector \u00b6 Bases: DataFileCollector Collects performance data files in a given path. __init__ () \u00b6 Creates an instance of PerformanceDataFileCollector. collect_data ( path , include_also_files_in_subdirectories = False ) \u00b6 Collects the data in a given path. Parameters: Name Type Description Default path pathlib . Path The path of the folder containing the files. required include_also_files_in_subdirectories bool Whether the data files in the subfolders should also be collected. False","title":"Evaluation"},{"location":"api/evaluation/#evaluation.file_type_hints_collector.FileTypeHintsCollector","text":"Collects the type hints of multiple .py files.","title":"FileTypeHintsCollector"},{"location":"api/evaluation/#evaluation.file_type_hints_collector.FileTypeHintsCollector.__init__","text":"Creates an instance of FileTypeHintsCollector.","title":"__init__()"},{"location":"api/evaluation/#evaluation.file_type_hints_collector.FileTypeHintsCollector.collect_data_from_file","text":"Collects the typehint data from a file. Parameters: Name Type Description Default root pathlib . Path The root folder path of the file. required filename str The file name. required","title":"collect_data_from_file()"},{"location":"api/evaluation/#evaluation.file_type_hints_collector.FileTypeHintsCollector.collect_data_from_files","text":"Collects the typehint data from multiple files. Parameters: Name Type Description Default root pathlib . Path The root folder path of the files. required filenames list [ str ] The file names. required","title":"collect_data_from_files()"},{"location":"api/evaluation/#evaluation.file_type_hints_collector.FileTypeHintsCollector.collect_data_from_folder","text":"Collects the typehint data from the files in the folder. Parameters: Name Type Description Default root pathlib . Path The root folder path. required folder pathlib . Path The path of the folder containing the files. required include_also_files_in_subdirectories bool Whether the type hints in the files in the subfolders should also be collected. True","title":"collect_data_from_folder()"},{"location":"api/evaluation/#evaluation.file_type_hints_collector.FileTypeHintsCollector.collect_data","text":"Collects the typehint data from the files in the provided file paths. Parameters: Name Type Description Default root pathlib . Path The root folder path. required file_paths Iterable [ pathlib . Path ] The file paths. required","title":"collect_data()"},{"location":"api/evaluation/#evaluation.metric_data_calculator.MetricDataCalculator","text":"Calculates the metric data.","title":"MetricDataCalculator"},{"location":"api/evaluation/#evaluation.metric_data_calculator.MetricDataCalculator.__init__","text":"Creates an instance of MetricDataCalculator.","title":"__init__()"},{"location":"api/evaluation/#evaluation.metric_data_calculator.MetricDataCalculator.add_filename_mapping","text":"Adds a mapping: generated file name -> original file name. Used to determine which generated file corresponds to which original file. calculate the metric data. Parameters: Name Type Description Default original_filename str The original file name. required generated_filename str The generated file name. required","title":"add_filename_mapping()"},{"location":"api/evaluation/#evaluation.metric_data_calculator.MetricDataCalculator.get_metric_data","text":"Calculates the metric data containing the correctness & completeness. Parameters: Name Type Description Default original_type_hint_data pd . DataFrame The original typehint data. required generated_type_hint_data pd . DataFrame The generated typehint data. required","title":"get_metric_data()"},{"location":"api/evaluation/#evaluation.metric_data_calculator.get_total_completeness_and_correctness","text":"Gets the total completeness & correctness of a given metric data. Parameters: Name Type Description Default metric_data pd . DataFrame The metric data. required Returns: Type Description tuple [ float , float ] The total completeness & correctness.","title":"get_total_completeness_and_correctness()"},{"location":"api/evaluation/#evaluation.normalize_types.normalize_type","text":"Gets the type union written as a type union using only | . Normalizes typing.Union, typing.Optional and | unions. Does also normalize inner type unions, for example: list[int | str]. Parameters: Name Type Description Default type_hint str The type hint name to normalize. required Returns: Type Description str the normalized type hint name.","title":"normalize_type()"},{"location":"api/evaluation/#evaluation.performance_data_file_collector.PerformanceDataFileCollector","text":"Bases: DataFileCollector Collects performance data files in a given path.","title":"PerformanceDataFileCollector"},{"location":"api/evaluation/#evaluation.performance_data_file_collector.PerformanceDataFileCollector.__init__","text":"Creates an instance of PerformanceDataFileCollector.","title":"__init__()"},{"location":"api/evaluation/#evaluation.performance_data_file_collector.PerformanceDataFileCollector.collect_data","text":"Collects the data in a given path. Parameters: Name Type Description Default path pathlib . Path The path of the folder containing the files. required include_also_files_in_subdirectories bool Whether the data files in the subfolders should also be collected. False","title":"collect_data()"},{"location":"api/optimising/","text":"Optimisation \u00b6 Bases: ABC Base class for tracing-related optimisations. If more optimisations need to be made, this class should be inherited from and the abstract methods are to be implemented __init__ ( fwm ) \u00b6 Construct an Optimisation for a stack frame Parameters: Name Type Description Default fwm FrameWithMetadata The frame that originally activates the Optimisation required status () abstractmethod \u00b6 Get the optimisation's status. See TriggerStatus for an explanation of how each one influences the impact of the optimization upon a frame in self.apply Returns: Type Description TriggerStatus The optimisation's status advance ( current_frame , traced ) abstractmethod \u00b6 Modify the optimization's internal state based on given frame. The traced DataFrame should be treated as read-only Parameters: Name Type Description Default current_frame FrameWithMetadata The current stack frame required traced pd . DataFrame The current trace data from the Tracer required __eq__ ( o ) abstractmethod \u00b6 Overloaded equality in order to check for already active / duplicate optimizations Returns: Type Description bool True if the other optimisation is of the same type and references the same frame TriggerStatus \u00b6 Bases: enum . IntEnum The different states an Optimisation can find itself in INACTIVE = 0 class-attribute \u00b6 Non-optimising, usually for gathering information during execution ENTRY = 1 class-attribute \u00b6 Optimising, first time the tracer will be turned off ONGOING = 2 class-attribute \u00b6 Optimising, tracer is continually being turned off EXITED = 3 class-attribute \u00b6 Non-optimising, the tracer will remove this optimisation at the first opportunity TypeStableLoop \u00b6 Bases: Optimisation Triggers when the types of instances within loop bodies are stable for the given amount of iterations. __init__ ( frame , iterations_until_entry = 5 ) \u00b6 Parameters: Name Type Description Default frame FrameWithMetadata Representation of stack frame that points to head of for loop required iterations_until_entry int The amount of iterations that shall pass until the optimisation starts firing 5 FrameWithMetadata dataclass \u00b6 A wrapper dataclass that takes the current frame and checks properties of the frame's state co_filename () property cached \u00b6 Get the filename of the code referenced by the frame f_lineno () property cached \u00b6 Get the line number referenced by the frame tokens () property cached \u00b6 Get a representation of the line currently being executed is_return () \u00b6 Return True if the frame represents a return statement is_break () \u00b6 Return True if the frame represents a break statement is_for_loop () \u00b6 Return True if the frame represents a for loop","title":"Optimising"},{"location":"api/optimising/#tracing.optimisation.base.Optimisation","text":"Bases: ABC Base class for tracing-related optimisations. If more optimisations need to be made, this class should be inherited from and the abstract methods are to be implemented","title":"Optimisation"},{"location":"api/optimising/#tracing.optimisation.base.Optimisation.__init__","text":"Construct an Optimisation for a stack frame Parameters: Name Type Description Default fwm FrameWithMetadata The frame that originally activates the Optimisation required","title":"__init__()"},{"location":"api/optimising/#tracing.optimisation.base.Optimisation.status","text":"Get the optimisation's status. See TriggerStatus for an explanation of how each one influences the impact of the optimization upon a frame in self.apply Returns: Type Description TriggerStatus The optimisation's status","title":"status()"},{"location":"api/optimising/#tracing.optimisation.base.Optimisation.advance","text":"Modify the optimization's internal state based on given frame. The traced DataFrame should be treated as read-only Parameters: Name Type Description Default current_frame FrameWithMetadata The current stack frame required traced pd . DataFrame The current trace data from the Tracer required","title":"advance()"},{"location":"api/optimising/#tracing.optimisation.base.Optimisation.__eq__","text":"Overloaded equality in order to check for already active / duplicate optimizations Returns: Type Description bool True if the other optimisation is of the same type and references the same frame","title":"__eq__()"},{"location":"api/optimising/#tracing.optimisation.enums.TriggerStatus","text":"Bases: enum . IntEnum The different states an Optimisation can find itself in","title":"TriggerStatus"},{"location":"api/optimising/#tracing.optimisation.enums.TriggerStatus.INACTIVE","text":"Non-optimising, usually for gathering information during execution","title":"INACTIVE"},{"location":"api/optimising/#tracing.optimisation.enums.TriggerStatus.ENTRY","text":"Optimising, first time the tracer will be turned off","title":"ENTRY"},{"location":"api/optimising/#tracing.optimisation.enums.TriggerStatus.ONGOING","text":"Optimising, tracer is continually being turned off","title":"ONGOING"},{"location":"api/optimising/#tracing.optimisation.enums.TriggerStatus.EXITED","text":"Non-optimising, the tracer will remove this optimisation at the first opportunity","title":"EXITED"},{"location":"api/optimising/#tracing.optimisation.looping.TypeStableLoop","text":"Bases: Optimisation Triggers when the types of instances within loop bodies are stable for the given amount of iterations.","title":"TypeStableLoop"},{"location":"api/optimising/#tracing.optimisation.looping.TypeStableLoop.__init__","text":"Parameters: Name Type Description Default frame FrameWithMetadata Representation of stack frame that points to head of for loop required iterations_until_entry int The amount of iterations that shall pass until the optimisation starts firing 5","title":"__init__()"},{"location":"api/optimising/#tracing.optimisation.utils.FrameWithMetadata","text":"A wrapper dataclass that takes the current frame and checks properties of the frame's state","title":"FrameWithMetadata"},{"location":"api/optimising/#tracing.optimisation.utils.FrameWithMetadata.co_filename","text":"Get the filename of the code referenced by the frame","title":"co_filename()"},{"location":"api/optimising/#tracing.optimisation.utils.FrameWithMetadata.f_lineno","text":"Get the line number referenced by the frame","title":"f_lineno()"},{"location":"api/optimising/#tracing.optimisation.utils.FrameWithMetadata.tokens","text":"Get a representation of the line currently being executed","title":"tokens()"},{"location":"api/optimising/#tracing.optimisation.utils.FrameWithMetadata.is_return","text":"Return True if the frame represents a return statement","title":"is_return()"},{"location":"api/optimising/#tracing.optimisation.utils.FrameWithMetadata.is_break","text":"Return True if the frame represents a break statement","title":"is_break()"},{"location":"api/optimising/#tracing.optimisation.utils.FrameWithMetadata.is_for_loop","text":"Return True if the frame represents a for loop","title":"is_for_loop()"},{"location":"api/tracing/","text":"trace ( c ) \u00b6 Execute the tracer upon a callable marked with this decorator. Serialises the accumulated trace data after the callable has finished to the location given by the config file. Uncaught exceptions are logged next to these pickled DataFrames. Supports performance benchmarking when specified in the config file. The implementation makes sure to preserve all arguments to the decorated callable, so that features like py.test's monkeypatching, fixtures etc. are all still supported. Parameters: Name Type Description Default c Callable [..., RetType ] Any given callable, with any amount of arguments, and any sort of return required TracerBase \u00b6 Bases: abc . ABC Base class for all Tracers. If more tracers need to be implemented, this class should be inherited from and the abstract method is to be implemented __init__ ( proj_path , stdlib_path , venv_path ) \u00b6 Construct instance with provided paths. Parameters: Name Type Description Default proj_path pathlib . Path Path to project's directory that shall be traced required stdlib_path pathlib . Path Path to standard library's directory of the Python binary used to run the project's tests required venv_path pathlib . Path Path to project's virtual environment's directory used to run the project's tests required start_trace () \u00b6 Starts the trace by calling sys.settrace and backing-up the previous one. All Python code run after this will now be traced. Parameters: Name Type Description Default self TracerBase An instance of a deriving class required active_trace () \u00b6 Wrapper around the start_trace and stop_trace methods for with statements. Python code run after this will no longer be traced. Parameters: Name Type Description Default self TracerBase An instance of a deriving class required stop_trace () \u00b6 Stops the trace and reinstates the previously set trace function. Also deduplicates the accumulated trace data. Parameters: Name Type Description Default self TracerBase An instance of a deriving class required NoOperationTracer \u00b6 Bases: TracerBase Tracer that does nothing except be invoked whenever a tracing-related event is emitted. Used to provide benchmarking, i.e. to measure the overhead by the \"real\" Tracer Tracer \u00b6 Bases: TracerBase Tracer that is invoked everytime a tracing-related event is emitted. Traces and stores information about each instance in a DataFrame using BatchTraceUpdate __init__ ( proj_path , stdlib_path , venv_path , apply_opts = True ) \u00b6 Construct instance with provided paths. Additionally accepts an extra argument that indicates whether optimisations should be enabled Parameters: Name Type Description Default proj_path pathlib . Path Path to project's directory that shall be traced required stdlib_path pathlib . Path Path to standard library's directory of the Python binary used to run the project's tests required venv_path pathlib . Path Path to project's virtual environment's directory used to run the project's tests required apply_opts bool When set to True, tries to optimise loop execution by turning off tracing if enough iterations have passed since any types have changed True TraceUpdate dataclass \u00b6 A simple dataclass holding the contents of a singular update Parameters: Name Type Description Default file_name pathlib . Path The file name in which the variables are declared required class_module str | None Module of the class the variable is in required class_name str | None Name of the class the variable is in required function_name str | None The function which declares the variable required line_number int The line number required category TraceDataCategory The data category of the row required names2types dict [ str , tuple [ str | None, str ]] A dictionary containing the variable name, the type's module and the type's name required BatchTraceUpdate dataclass \u00b6 A builder-pattern style interface for each relevant category, allowing updates to be chained as each event requires. After all updates have been handled, a DataFrame can be produced that is to added to the otherwise accumulated trace data. The constructor accepts values that are used by default to create instances of TraceUpdate , unless overwritten by an argument in one of the builder methods. TRACE_MAP is defined as dict[str, tuple[str | None, str]] , which is a map of identifiers to (module name, type name). The module_name is None if the type is builtin, such as int, str, float etc. Parameters: Name Type Description Default file_name pathlib . Path The file name in which the variables are declared required class_module str | None Module of the class the variable is in required class_name str | None Name of the class the variable is in required function_name str The function which declares the variable required line_number int The line number required local_variables ( line_number , names2types ) \u00b6 Create an update consisting of local variables Parameters: Name Type Description Default line_number int Because the line number that a variable is written on is not the same as the one it is put on the stack, this must be manually specified required names2types TRACE_MAP Names of local variables mapped to the module and type names of their types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch global_variables ( names2types ) \u00b6 Create an update consisting of global variables. Because they are stateful, their line number is always 0, and can only be differentiated by their name and the file they occur in Parameters: Name Type Description Default names2types TRACE_MAP Names of global variables mapped to the module and type names of their types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch returns ( names2types ) \u00b6 Create an update consisting of return types from functions. Their line number is always 0, so that unifiers can group them together appropriately later. Parameters: Name Type Description Default names2types TRACE_MAP Names of functions mapped to the module and type name of their return types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch parameters ( names2types ) \u00b6 Create an update consisting of parameters for a callable. Parameters: Name Type Description Default names2types TRACE_MAP Names of the parameters to a callable mapped to the module and type names of their types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch members ( names2types ) \u00b6 Create an update consisting of attributes of a class. Because they are stateful, their line number is always 0, and can only be differentiated by the file they occur in, their identifier and the class they occur in Parameters: Name Type Description Default names2types TRACE_MAP Names of the members of a class mapped to the module and type names of their types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch to_frame () \u00b6 Consume this batch of updates in order to produce a DataFrame. Parameters: Name Type Description Default self BatchTraceUpdate Nothing else :) required Returns: Type Description pd . DataFrame A DataFrame encompassing the entire batch","title":"Tracing"},{"location":"api/tracing/#tracing.decorators.trace","text":"Execute the tracer upon a callable marked with this decorator. Serialises the accumulated trace data after the callable has finished to the location given by the config file. Uncaught exceptions are logged next to these pickled DataFrames. Supports performance benchmarking when specified in the config file. The implementation makes sure to preserve all arguments to the decorated callable, so that features like py.test's monkeypatching, fixtures etc. are all still supported. Parameters: Name Type Description Default c Callable [..., RetType ] Any given callable, with any amount of arguments, and any sort of return required","title":"trace()"},{"location":"api/tracing/#tracing.tracer.TracerBase","text":"Bases: abc . ABC Base class for all Tracers. If more tracers need to be implemented, this class should be inherited from and the abstract method is to be implemented","title":"TracerBase"},{"location":"api/tracing/#tracing.tracer.TracerBase.__init__","text":"Construct instance with provided paths. Parameters: Name Type Description Default proj_path pathlib . Path Path to project's directory that shall be traced required stdlib_path pathlib . Path Path to standard library's directory of the Python binary used to run the project's tests required venv_path pathlib . Path Path to project's virtual environment's directory used to run the project's tests required","title":"__init__()"},{"location":"api/tracing/#tracing.tracer.TracerBase.start_trace","text":"Starts the trace by calling sys.settrace and backing-up the previous one. All Python code run after this will now be traced. Parameters: Name Type Description Default self TracerBase An instance of a deriving class required","title":"start_trace()"},{"location":"api/tracing/#tracing.tracer.TracerBase.active_trace","text":"Wrapper around the start_trace and stop_trace methods for with statements. Python code run after this will no longer be traced. Parameters: Name Type Description Default self TracerBase An instance of a deriving class required","title":"active_trace()"},{"location":"api/tracing/#tracing.tracer.TracerBase.stop_trace","text":"Stops the trace and reinstates the previously set trace function. Also deduplicates the accumulated trace data. Parameters: Name Type Description Default self TracerBase An instance of a deriving class required","title":"stop_trace()"},{"location":"api/tracing/#tracing.tracer.NoOperationTracer","text":"Bases: TracerBase Tracer that does nothing except be invoked whenever a tracing-related event is emitted. Used to provide benchmarking, i.e. to measure the overhead by the \"real\" Tracer","title":"NoOperationTracer"},{"location":"api/tracing/#tracing.tracer.Tracer","text":"Bases: TracerBase Tracer that is invoked everytime a tracing-related event is emitted. Traces and stores information about each instance in a DataFrame using BatchTraceUpdate","title":"Tracer"},{"location":"api/tracing/#tracing.tracer.Tracer.__init__","text":"Construct instance with provided paths. Additionally accepts an extra argument that indicates whether optimisations should be enabled Parameters: Name Type Description Default proj_path pathlib . Path Path to project's directory that shall be traced required stdlib_path pathlib . Path Path to standard library's directory of the Python binary used to run the project's tests required venv_path pathlib . Path Path to project's virtual environment's directory used to run the project's tests required apply_opts bool When set to True, tries to optimise loop execution by turning off tracing if enough iterations have passed since any types have changed True","title":"__init__()"},{"location":"api/tracing/#tracing.trace_update.TraceUpdate","text":"A simple dataclass holding the contents of a singular update Parameters: Name Type Description Default file_name pathlib . Path The file name in which the variables are declared required class_module str | None Module of the class the variable is in required class_name str | None Name of the class the variable is in required function_name str | None The function which declares the variable required line_number int The line number required category TraceDataCategory The data category of the row required names2types dict [ str , tuple [ str | None, str ]] A dictionary containing the variable name, the type's module and the type's name required","title":"TraceUpdate"},{"location":"api/tracing/#tracing.trace_update.BatchTraceUpdate","text":"A builder-pattern style interface for each relevant category, allowing updates to be chained as each event requires. After all updates have been handled, a DataFrame can be produced that is to added to the otherwise accumulated trace data. The constructor accepts values that are used by default to create instances of TraceUpdate , unless overwritten by an argument in one of the builder methods. TRACE_MAP is defined as dict[str, tuple[str | None, str]] , which is a map of identifiers to (module name, type name). The module_name is None if the type is builtin, such as int, str, float etc. Parameters: Name Type Description Default file_name pathlib . Path The file name in which the variables are declared required class_module str | None Module of the class the variable is in required class_name str | None Name of the class the variable is in required function_name str The function which declares the variable required line_number int The line number required","title":"BatchTraceUpdate"},{"location":"api/tracing/#tracing.trace_update.BatchTraceUpdate.local_variables","text":"Create an update consisting of local variables Parameters: Name Type Description Default line_number int Because the line number that a variable is written on is not the same as the one it is put on the stack, this must be manually specified required names2types TRACE_MAP Names of local variables mapped to the module and type names of their types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch","title":"local_variables()"},{"location":"api/tracing/#tracing.trace_update.BatchTraceUpdate.global_variables","text":"Create an update consisting of global variables. Because they are stateful, their line number is always 0, and can only be differentiated by their name and the file they occur in Parameters: Name Type Description Default names2types TRACE_MAP Names of global variables mapped to the module and type names of their types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch","title":"global_variables()"},{"location":"api/tracing/#tracing.trace_update.BatchTraceUpdate.returns","text":"Create an update consisting of return types from functions. Their line number is always 0, so that unifiers can group them together appropriately later. Parameters: Name Type Description Default names2types TRACE_MAP Names of functions mapped to the module and type name of their return types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch","title":"returns()"},{"location":"api/tracing/#tracing.trace_update.BatchTraceUpdate.parameters","text":"Create an update consisting of parameters for a callable. Parameters: Name Type Description Default names2types TRACE_MAP Names of the parameters to a callable mapped to the module and type names of their types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch","title":"parameters()"},{"location":"api/tracing/#tracing.trace_update.BatchTraceUpdate.members","text":"Create an update consisting of attributes of a class. Because they are stateful, their line number is always 0, and can only be differentiated by the file they occur in, their identifier and the class they occur in Parameters: Name Type Description Default names2types TRACE_MAP Names of the members of a class mapped to the module and type names of their types required Returns: Type Description BatchTraceUpdate A reference to newly updated batch","title":"members()"},{"location":"api/tracing/#tracing.trace_update.BatchTraceUpdate.to_frame","text":"Consume this batch of updates in order to produce a DataFrame. Parameters: Name Type Description Default self BatchTraceUpdate Nothing else :) required Returns: Type Description pd . DataFrame A DataFrame encompassing the entire batch","title":"to_frame()"},{"location":"api/typegen/","text":"TypeHintGenerator \u00b6 Bases: abc . ABC Base class for different generation styles of type hints TypeHintTransformer \u00b6 Bases: cst . CSTTransformer Transforms the CST by adding the traced type hints without modifying the original type hints. RemoveAllTypeHintsTransformer \u00b6 Bases: cst . CSTTransformer Transforms the CST by removing all type hints. leave_FunctionDef ( _ , updated_node ) \u00b6 Removes the return type hint of the function def node. Parameters: Name Type Description Default updated_node cst . FunctionDef The updated node. required Returns: Type Description cst . FunctionDef The updated node without any return type hint. leave_Param ( _ , updated_node ) \u00b6 Removes the type hint of the parameter node. Parameters: Name Type Description Default updated_node cst . Param The updated node. required Returns: Type Description cst . Param The updated node without any return type hint. leave_AnnAssign ( original_node , _ ) \u00b6 Removes the type hint of the annotated assignment node. Parameters: Name Type Description Default original_node cst . AnnAssign The original node. required Returns: Type Description cst . Assign | cst . AnnAssign | cst . RemovalSentinel The removal of the original node from the parent if there isn't any assigned value or a new node matching the original node without any type hint. EvaluationInlineGenerator \u00b6 Bases: InlineGenerator Overwrites the files by removing the existing and then adding the traced type hints. ImportUnionTransformer \u00b6 Bases: cst . CSTTransformer Transforms the CST by adding the ImportFrom node (from typing import Union) if the corresponding code contains a union type hint. __init__ () \u00b6 Creates an instance of ImportUnionTransformer. leave_Module ( _ , updated_node ) \u00b6 Adds the ImportFrom node to the CST if a union type hint has been found. Parameters: Name Type Description Default updated_node cst . Module The updated node. required Returns: Type Description cst . Module The updated node with the added ImportFrom node if a union type hint has been found, otherwise the updated node without any changes. visit_Param ( node ) \u00b6 Checks whether the parameter node contains a union type hint. Parameters: Name Type Description Default node cst . Param The visited node. required visit_FunctionDef_returns ( node ) \u00b6 Checks whether the function def node contains a union type hint for the return type. Parameters: Name Type Description Default node cst . FunctionDef The visited node. required visit_AnnAssign ( node ) \u00b6 Checks whether the annotated assignment node contains a union type hint. Parameters: Name Type Description Default node cst . AnnAssign The visited node. required MyPyHintTransformer \u00b6 Bases: cst . CSTTransformer Replaces the CST with the corresponding stub CST, generated using mypy.stubgen. leave_Module ( _ , updated_node ) \u00b6 Replaces the CST with the corresponding stub CST, generated using mypy.stubgen. Parameters: Name Type Description Default updated_node cst . Module The updated node. required Returns: Type Description cst . Module The stub CST. StubFileGenerator \u00b6 Bases: TypeHintGenerator Generates stub files using mypy.stubgen. TraceDataFilter \u00b6 Bases: abc . ABC Base class for different trace data filters. To implement a new filter class, inherit from this class and overwrite the abstract methods. apply ( trace_data ) abstractmethod \u00b6 Processes the provided trace data and returns the processed trace data and the difference between the old and new data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. TraceDataFilterList \u00b6 Bases: TraceDataFilter Applies the filters in this list on the trace data. append ( trace_data_filter ) \u00b6 Appends a filter to the list. Parameters: Name Type Description Default trace_data_filter TraceDataFilter The filter to append. required apply ( trace_data ) \u00b6 Applies the filters on the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. DropDuplicatesFilter \u00b6 Bases: TraceDataFilter Drops all duplicates in the trace data. apply ( trace_data ) \u00b6 Drops the duplicates in the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. MinThresholdFilter \u00b6 Bases: TraceDataFilter Drops all rows whose types appear less often than the minimum threshold. apply ( trace_data ) \u00b6 Drops all rows whose types appear less often than the minimum threshold in the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. DropTestFunctionDataFilter \u00b6 Bases: TraceDataFilter Drops all data about test functions. apply ( trace_data ) \u00b6 Drops the data about test functions in the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. DropVariablesOfMultipleTypesFilter \u00b6 Bases: TraceDataFilter Drops rows containing variables of multiple types. apply ( trace_data ) \u00b6 Drops rows containing variables if the amount of inferred types is higher than self.min_amount_types_to_drop and returns the processed data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. KeepOnlyFirstFilter \u00b6 Bases: TraceDataFilter Keeps only the first row of each variable. apply ( trace_data ) \u00b6 Keeps only the first row of each variable in the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. UnifySubTypesFilter \u00b6 Bases: TraceDataFilter Unify rows containing types in the data with their common base type. apply ( trace_data ) \u00b6 Unify rows containing types using their common base type. If only_unify_if_base_was_traced is True, only rows of types whose base type is already in the data are replaced. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. UnionFilter \u00b6 Bases: TraceDataFilter Unify rows containing types in the data with the union of these types. apply ( trace_data ) \u00b6 Unify rows containing types using corresponding type union. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data. TraceDataFileCollector \u00b6 Bases: DataFileCollector Collects trace data files in a given path. __init__ () \u00b6 Creates an instance of TraceDataFileCollector. collect_data ( path , include_also_files_in_subdirectories = True ) \u00b6 Collects the data in a given path. Parameters: Name Type Description Default path pathlib . Path The path of the folder containing the files. required include_also_files_in_subdirectories bool Whether the data files in the subfolders should also be collected. True","title":"Annotating"},{"location":"api/typegen/#typegen.strats.gen.TypeHintGenerator","text":"Bases: abc . ABC Base class for different generation styles of type hints","title":"TypeHintGenerator"},{"location":"api/typegen/#typegen.strats.inline.TypeHintTransformer","text":"Bases: cst . CSTTransformer Transforms the CST by adding the traced type hints without modifying the original type hints.","title":"TypeHintTransformer"},{"location":"api/typegen/#typegen.strats.eval_inline.RemoveAllTypeHintsTransformer","text":"Bases: cst . CSTTransformer Transforms the CST by removing all type hints.","title":"RemoveAllTypeHintsTransformer"},{"location":"api/typegen/#typegen.strats.eval_inline.RemoveAllTypeHintsTransformer.leave_FunctionDef","text":"Removes the return type hint of the function def node. Parameters: Name Type Description Default updated_node cst . FunctionDef The updated node. required Returns: Type Description cst . FunctionDef The updated node without any return type hint.","title":"leave_FunctionDef()"},{"location":"api/typegen/#typegen.strats.eval_inline.RemoveAllTypeHintsTransformer.leave_Param","text":"Removes the type hint of the parameter node. Parameters: Name Type Description Default updated_node cst . Param The updated node. required Returns: Type Description cst . Param The updated node without any return type hint.","title":"leave_Param()"},{"location":"api/typegen/#typegen.strats.eval_inline.RemoveAllTypeHintsTransformer.leave_AnnAssign","text":"Removes the type hint of the annotated assignment node. Parameters: Name Type Description Default original_node cst . AnnAssign The original node. required Returns: Type Description cst . Assign | cst . AnnAssign | cst . RemovalSentinel The removal of the original node from the parent if there isn't any assigned value or a new node matching the original node without any type hint.","title":"leave_AnnAssign()"},{"location":"api/typegen/#typegen.strats.eval_inline.EvaluationInlineGenerator","text":"Bases: InlineGenerator Overwrites the files by removing the existing and then adding the traced type hints.","title":"EvaluationInlineGenerator"},{"location":"api/typegen/#typegen.strats.stub.ImportUnionTransformer","text":"Bases: cst . CSTTransformer Transforms the CST by adding the ImportFrom node (from typing import Union) if the corresponding code contains a union type hint.","title":"ImportUnionTransformer"},{"location":"api/typegen/#typegen.strats.stub.ImportUnionTransformer.__init__","text":"Creates an instance of ImportUnionTransformer.","title":"__init__()"},{"location":"api/typegen/#typegen.strats.stub.ImportUnionTransformer.leave_Module","text":"Adds the ImportFrom node to the CST if a union type hint has been found. Parameters: Name Type Description Default updated_node cst . Module The updated node. required Returns: Type Description cst . Module The updated node with the added ImportFrom node if a union type hint has been found, otherwise the updated node without any changes.","title":"leave_Module()"},{"location":"api/typegen/#typegen.strats.stub.ImportUnionTransformer.visit_Param","text":"Checks whether the parameter node contains a union type hint. Parameters: Name Type Description Default node cst . Param The visited node. required","title":"visit_Param()"},{"location":"api/typegen/#typegen.strats.stub.ImportUnionTransformer.visit_FunctionDef_returns","text":"Checks whether the function def node contains a union type hint for the return type. Parameters: Name Type Description Default node cst . FunctionDef The visited node. required","title":"visit_FunctionDef_returns()"},{"location":"api/typegen/#typegen.strats.stub.ImportUnionTransformer.visit_AnnAssign","text":"Checks whether the annotated assignment node contains a union type hint. Parameters: Name Type Description Default node cst . AnnAssign The visited node. required","title":"visit_AnnAssign()"},{"location":"api/typegen/#typegen.strats.stub.MyPyHintTransformer","text":"Bases: cst . CSTTransformer Replaces the CST with the corresponding stub CST, generated using mypy.stubgen.","title":"MyPyHintTransformer"},{"location":"api/typegen/#typegen.strats.stub.MyPyHintTransformer.leave_Module","text":"Replaces the CST with the corresponding stub CST, generated using mypy.stubgen. Parameters: Name Type Description Default updated_node cst . Module The updated node. required Returns: Type Description cst . Module The stub CST.","title":"leave_Module()"},{"location":"api/typegen/#typegen.strats.stub.StubFileGenerator","text":"Bases: TypeHintGenerator Generates stub files using mypy.stubgen.","title":"StubFileGenerator"},{"location":"api/typegen/#typegen.unification.filter_base.TraceDataFilter","text":"Bases: abc . ABC Base class for different trace data filters. To implement a new filter class, inherit from this class and overwrite the abstract methods.","title":"TraceDataFilter"},{"location":"api/typegen/#typegen.unification.filter_base.TraceDataFilter.apply","text":"Processes the provided trace data and returns the processed trace data and the difference between the old and new data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.unification.filter_base.TraceDataFilterList","text":"Bases: TraceDataFilter Applies the filters in this list on the trace data.","title":"TraceDataFilterList"},{"location":"api/typegen/#typegen.unification.filter_base.TraceDataFilterList.append","text":"Appends a filter to the list. Parameters: Name Type Description Default trace_data_filter TraceDataFilter The filter to append. required","title":"append()"},{"location":"api/typegen/#typegen.unification.filter_base.TraceDataFilterList.apply","text":"Applies the filters on the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.unification.drop_dupes.DropDuplicatesFilter","text":"Bases: TraceDataFilter Drops all duplicates in the trace data.","title":"DropDuplicatesFilter"},{"location":"api/typegen/#typegen.unification.drop_dupes.DropDuplicatesFilter.apply","text":"Drops the duplicates in the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.unification.drop_min_threshold.MinThresholdFilter","text":"Bases: TraceDataFilter Drops all rows whose types appear less often than the minimum threshold.","title":"MinThresholdFilter"},{"location":"api/typegen/#typegen.unification.drop_min_threshold.MinThresholdFilter.apply","text":"Drops all rows whose types appear less often than the minimum threshold in the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.unification.drop_test_func.DropTestFunctionDataFilter","text":"Bases: TraceDataFilter Drops all data about test functions.","title":"DropTestFunctionDataFilter"},{"location":"api/typegen/#typegen.unification.drop_test_func.DropTestFunctionDataFilter.apply","text":"Drops the data about test functions in the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.unification.drop_vars.DropVariablesOfMultipleTypesFilter","text":"Bases: TraceDataFilter Drops rows containing variables of multiple types.","title":"DropVariablesOfMultipleTypesFilter"},{"location":"api/typegen/#typegen.unification.drop_vars.DropVariablesOfMultipleTypesFilter.apply","text":"Drops rows containing variables if the amount of inferred types is higher than self.min_amount_types_to_drop and returns the processed data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.unification.keep_only_first.KeepOnlyFirstFilter","text":"Bases: TraceDataFilter Keeps only the first row of each variable.","title":"KeepOnlyFirstFilter"},{"location":"api/typegen/#typegen.unification.keep_only_first.KeepOnlyFirstFilter.apply","text":"Keeps only the first row of each variable in the provided trace data and returns the processed trace data. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.unification.subtyping.UnifySubTypesFilter","text":"Bases: TraceDataFilter Unify rows containing types in the data with their common base type.","title":"UnifySubTypesFilter"},{"location":"api/typegen/#typegen.unification.subtyping.UnifySubTypesFilter.apply","text":"Unify rows containing types using their common base type. If only_unify_if_base_was_traced is True, only rows of types whose base type is already in the data are replaced. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.unification.union.UnionFilter","text":"Bases: TraceDataFilter Unify rows containing types in the data with the union of these types.","title":"UnionFilter"},{"location":"api/typegen/#typegen.unification.union.UnionFilter.apply","text":"Unify rows containing types using corresponding type union. Parameters: Name Type Description Default trace_data pd . DataFrame The provided trace data to process. required Returns: Type Description pd . DataFrame The processed trace data.","title":"apply()"},{"location":"api/typegen/#typegen.trace_data_file_collector.TraceDataFileCollector","text":"Bases: DataFileCollector Collects trace data files in a given path.","title":"TraceDataFileCollector"},{"location":"api/typegen/#typegen.trace_data_file_collector.TraceDataFileCollector.__init__","text":"Creates an instance of TraceDataFileCollector.","title":"__init__()"},{"location":"api/typegen/#typegen.trace_data_file_collector.TraceDataFileCollector.collect_data","text":"Collects the data in a given path. Parameters: Name Type Description Default path pathlib . Path The path of the folder containing the files. required include_also_files_in_subdirectories bool Whether the data files in the subfolders should also be collected. True","title":"collect_data()"},{"location":"misc/config/","text":"Principles \u00b6 For this project's multi-stage workflow, some variables remain constant across multiple commands. For example, the paths necessary to differentiate between standard project types, standard library types and types from third-party dependencies in the virtualenv are needed for both the tracing and unification processes. All such variables are stored in a pytypes.toml file in the root of the project to trace, which will be read in by the program without the user having to respecify them. Example \u00b6 The following configuration is used for a project called PyTypes . The project is located in /home/name/repos/pytypes , the used Python binary's standard library is located at /usr/lib/python3.10 , and the virtual environment is located at /home/name/.cache/pypoetry/venv/pytypes-xvtnrWJT . To read up on why these paths are necessary, read up on the Resolver class and how types are stored into our trace data . Furthermore, customisable unifiers that are used during the annotation generation process are stored by a name and identified by the kind attribute. To read up on how these unifiers come into play, read up on the annotation generation process . [pytypes] project = \"PyTypes\" proj_path = \"/home/name/repos/pytypes\" stdlib_path = \"/usr/lib/python3.10\" venv_path = \"/home/name/.cache/pypoetry/venv/pytypes-xvtnrWJT\" [[unifier]] name = \"remove_dups\" kind = \"dedup\" [[unifier]] name = \"ignore_test\" kind = \"drop_test\" test_name_pat = \"test_\" [[unifier]] name = \"drop_implicit_2\" kind = \"drop_mult_var\" [[unifier]] name = \"drop_explicit_5\" kind = \"drop_mult_var\" min_amount_types_to_drop = 5 [[unifier]] name = \"unify_subtypes_relaxed\" kind = \"unify_subty\" [[unifier]] name = \"min_threshold\" kind = \"drop_min_threshold\" min_threshold = 0.3 [[unifier]] name = \"unify\" kind = \"union\"","title":"Configuration"},{"location":"misc/config/#principles","text":"For this project's multi-stage workflow, some variables remain constant across multiple commands. For example, the paths necessary to differentiate between standard project types, standard library types and types from third-party dependencies in the virtualenv are needed for both the tracing and unification processes. All such variables are stored in a pytypes.toml file in the root of the project to trace, which will be read in by the program without the user having to respecify them.","title":"Principles"},{"location":"misc/config/#example","text":"The following configuration is used for a project called PyTypes . The project is located in /home/name/repos/pytypes , the used Python binary's standard library is located at /usr/lib/python3.10 , and the virtual environment is located at /home/name/.cache/pypoetry/venv/pytypes-xvtnrWJT . To read up on why these paths are necessary, read up on the Resolver class and how types are stored into our trace data . Furthermore, customisable unifiers that are used during the annotation generation process are stored by a name and identified by the kind attribute. To read up on how these unifiers come into play, read up on the annotation generation process . [pytypes] project = \"PyTypes\" proj_path = \"/home/name/repos/pytypes\" stdlib_path = \"/usr/lib/python3.10\" venv_path = \"/home/name/.cache/pypoetry/venv/pytypes-xvtnrWJT\" [[unifier]] name = \"remove_dups\" kind = \"dedup\" [[unifier]] name = \"ignore_test\" kind = \"drop_test\" test_name_pat = \"test_\" [[unifier]] name = \"drop_implicit_2\" kind = \"drop_mult_var\" [[unifier]] name = \"drop_explicit_5\" kind = \"drop_mult_var\" min_amount_types_to_drop = 5 [[unifier]] name = \"unify_subtypes_relaxed\" kind = \"unify_subty\" [[unifier]] name = \"min_threshold\" kind = \"drop_min_threshold\" min_threshold = 0.3 [[unifier]] name = \"unify\" kind = \"union\"","title":"Example"},{"location":"misc/resolver/","text":"Principles \u00b6 The project has a need for a bidirectional lookup of types and modules; When the tracer implementation finds an instance that needs logging, it can query the Resolver for a module path and the instance's type's qualified name. Similary, when given strings containing a module path and a type's qualified name, the Resolver is capable of loading the requested type from its file. API \u00b6 Retrieving Module Path and Qualified Type Name from a type \u00b6 The process of type to module & path is performed by querying the given type using the __module__ and __file__ , together with sys.modules . sys.modules can be queried using a type 's __module__ attribute. For builtin types, this query delivers \"builtins\" , which is caught as an early-return. Using the [ __file__ ] attribute on the query's result, using the paths specified in the config file , the Resolver can determine by detection of relative paths whether the requested type is from the traced project, the standard library, or from a third-party dependency. Examples: \u00b6 >>> resolver . get_module_and_name ( ty = int ) ( None , 'int' ) >>> resolver . get_module_and_name ( ty = pathlib . Path ) ( 'pathlib' , 'Path' ) >>> resolver . get_module_and_name ( ty = fractions . Fraction ) ( 'fractions' , 'Fraction' ) >>> class Outer : ... class Inner : ... class EvenMoreInner : ... ... >>> r . get_module_and_name ( ty = Outer . Inner . EvenMoreInner ) ( '__main__' , 'Outer.Inner.EvenMoreInner' ) Creating a type from a Module Path and Qualified Type Name \u00b6 The process of module & path to type is facilitated by Python's importlib , which enables dynamic imports from modules. Examples: \u00b6 >>> resolver . type_lookup ( module_name = None , type_name = \"int\" ) < class ' int '> >>> resolver . type_lookup ( module_name = \"pathlib\" , type_name = \"Path\" ) < class ' pathlib . Path '> >>> resolver . type_lookup ( module_name = \"fractions\" , type_name = \"Fraction\" ) < class ' fractions . Fraction '> >>> class Outer : ... class Inner : ... class EvenMoreInner : ... ... >>> resolver . type_lookup ( ... module_name = \"__main__\" , ... type_name = \"Outer.Inner.EvenMoreInner\" ) < class ' __main__ . Outer . Inner . EvenMoreInner '> (The final example doesn't work in the REPL, because the repl cannot be passed as a project path, but tests show that it works in practice)","title":"Types, Modules & Qualified Names"},{"location":"misc/resolver/#principles","text":"The project has a need for a bidirectional lookup of types and modules; When the tracer implementation finds an instance that needs logging, it can query the Resolver for a module path and the instance's type's qualified name. Similary, when given strings containing a module path and a type's qualified name, the Resolver is capable of loading the requested type from its file.","title":"Principles"},{"location":"misc/resolver/#api","text":"","title":"API"},{"location":"misc/resolver/#retrieving-module-path-and-qualified-type-name-from-a-type","text":"The process of type to module & path is performed by querying the given type using the __module__ and __file__ , together with sys.modules . sys.modules can be queried using a type 's __module__ attribute. For builtin types, this query delivers \"builtins\" , which is caught as an early-return. Using the [ __file__ ] attribute on the query's result, using the paths specified in the config file , the Resolver can determine by detection of relative paths whether the requested type is from the traced project, the standard library, or from a third-party dependency.","title":"Retrieving Module Path and Qualified Type Name from a type"},{"location":"misc/resolver/#examples","text":">>> resolver . get_module_and_name ( ty = int ) ( None , 'int' ) >>> resolver . get_module_and_name ( ty = pathlib . Path ) ( 'pathlib' , 'Path' ) >>> resolver . get_module_and_name ( ty = fractions . Fraction ) ( 'fractions' , 'Fraction' ) >>> class Outer : ... class Inner : ... class EvenMoreInner : ... ... >>> r . get_module_and_name ( ty = Outer . Inner . EvenMoreInner ) ( '__main__' , 'Outer.Inner.EvenMoreInner' )","title":"Examples:"},{"location":"misc/resolver/#creating-a-type-from-a-module-path-and-qualified-type-name","text":"The process of module & path to type is facilitated by Python's importlib , which enables dynamic imports from modules.","title":"Creating a type from a Module Path and Qualified Type Name"},{"location":"misc/resolver/#examples_1","text":">>> resolver . type_lookup ( module_name = None , type_name = \"int\" ) < class ' int '> >>> resolver . type_lookup ( module_name = \"pathlib\" , type_name = \"Path\" ) < class ' pathlib . Path '> >>> resolver . type_lookup ( module_name = \"fractions\" , type_name = \"Fraction\" ) < class ' fractions . Fraction '> >>> class Outer : ... class Inner : ... class EvenMoreInner : ... ... >>> resolver . type_lookup ( ... module_name = \"__main__\" , ... type_name = \"Outer.Inner.EvenMoreInner\" ) < class ' __main__ . Outer . Inner . EvenMoreInner '> (The final example doesn't work in the REPL, because the repl cannot be passed as a project path, but tests show that it works in practice)","title":"Examples:"},{"location":"workflow/annotating/","text":"Functionality \u00b6 The typegen module contains classes & functions to unify trace data and generate files with type hints. It also offers a command to execute the typegen workflow. \u03bb poetry run python main.py typegen --help Usage: main.py typegen [OPTIONS] Generate type hinted files using trace data Options: -p, --path PATH Path to project directory [required] -u, --unifiers TEXT Unifier to apply, as given by `name` in pytypes.toml under [[unifier]] -g, --gen-strat [stub|inline|eval_inline] Select a strategy for generating type hints [required] -v, --verbose INFO if not given, else DEBUG --help Show this message and exit. Example usage: \u03bb poetry run python main.py typegen \\ -p project_path -g eval_inline \\ -u mt -u dupl -u mult2 -u dupl -u first Foundations & Principles \u00b6 The project's approach to annotating is CST-based (Concrete-Syntax-Tree) transformation. A CST differs from an AST in that it keeps all formatting details, including comments, whitespace and parantheses, and is therefore a fitting choice for the project, as only minimals modifications to a repository's code should occur, i.e. annotations and decorators for tracing. In regards thereto, Python's AST module is a poor choice, as it only contains elements that are necessary for code execution, i.e. it drops extraneous newlines, changes all quote signs to single quotes, and perhaps worst of all, it removes all single-line comments. The project offers both inline and stub-based annotation generation, whose mechanics, both shared and individual, have been split into CST transformers. By reading in files that have been traced, trace data can be segmented on a per-file basis. From this per-file basis trace data, annotations (also called type hints) can be generated for each file using the aforementioned transformers, and output appropriately. Unification \u00b6 The trace data must be cleaned and appropriately unified to remove redundant data so that at most one type hint can be associated with each traced instance. To this extent, unifiers with a common interface have been implemented to cover unification needs. The unifiers are applied to the trace data in the order specified on the command line; the value given to each -u flag references a unifier by the name key given in the config file . The examples in the following section will contain \"Category\", \"FunctionName\", \"VarName\", \"TypeModule\" and \"Type\" at a minimum for brevity's sake. Unifiers \u00b6 Every unifier performs a different operation upon the trace data. These can largely be segmented into two categories, namely 'filtering' and 'reducing'. The former removes occurrences of trace data that are undesirable, and the latter groups rows and make replacements where appropriate. Filtering Unifiers \u00b6 Drop Duplicates \u00b6 While the tracer implementation may deduplicate trace data after halting, when the trace data is loaded into memory, every test that shares a call-path usually holds the same information, which is redundant, and can therefore be removed. Example: Configuration File: [[unifier]] name = \"remove_dups\" kind = \"dedup\" Trace Data: FunctionName VarName TypeModule Type test_function local_variable NA str function parameter NA int function parameter NA int After applying the filter: FunctionName VarName TypeModule Type test_function local_variable NA str function parameter NA int Drop Test Functions \u00b6 The project always applies its decorators to test functions and methods , which leads to trace information about the test also being stored, and possibly generated during the annotation process . If the user does not want to retain this information, then this filter should be applied, which simply drops all rows that reference testing callables. Example: Configuration File: [[unifier]] name = \"ignore_test\" kind = \"drop_test\" test_name_pat = \"test_\" Trace Data: Category FunctionName VarName TypeModule Type 1 test_function local_variable NA str 2 function parameter NA int 2 function parameter NA int After applying the filter: Category FunctionName VarName TypeModule Type 2 function parameter NA int 2 function parameter NA int Min-Threshold \u00b6 Drop all rows whose types appear less often than the minimum threshold. This is a simple attempt to detect API misusage in tests; if a statistically significant amount of tests use a certain signature, and a very low amount of other tests use a different one, then this unifier will remove those rows. Example: Configuration File: [[unifier]] name = \"min_threshold\" kind = \"drop_min_threshold\" min_threshold = 0.3 Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA str After applying the filter: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA int Drop of multiple types \u00b6 Drops rows containing variables of multiple types. It can be used to drop variables which do not have any distinct type hint as they have too many different type hints. Example: Configuration File: [[unifier]] name = \"drop_explicit_3\" kind = \"drop_mult_var\" min_amount_types_to_drop = 3 Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter NA bool 2 parameter NA float 2 parameter2 NA int 2 parameter2 NA int 2 parameter2 NA str After applying the filter: Category VarName TypeModule Type 2 parameter2 NA int 2 parameter2 NA int 2 parameter2 NA str Keep only first \u00b6 Keeps only the first row of each variable. It can be used to ensure that each variable in the trace data has only one type hint. Thus, it is often used as the last filter. Example: Configuration File: [[unifier]] name = \"keep_first\" kind = \"keep_only_first\" Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter2 module_name SubClass 2 parameter2 module_name BaseClass After applying the filter: Category VarName TypeModule Type 2 parameter NA int 2 parameter2 module_name SubClass Reducing Unifiers \u00b6 Subtypes & Common Interfaces \u00b6 Replaces rows containing types of the same variable in the data with their earliest common base type. This unifier uses the Resolver implementation to load the MRO s for such rows in order to find the said shared base type. The instance can also be defined so that only type hints are replaced if the common base type is also in the trace data. No replacement occurs for undesirable base types, such as abc.ABC , abc.ABCMeta and object . Example: Configuration File: [[unifier]] name = \"unify_subtypes_strict\" kind = \"unify_subty\" only_unify_if_base_was_traced = true Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter2 module_name SubClass 2 parameter2 module_name BaseClass (In this example, module_name.SubClass inherits from module_name.BaseClass.) After applying the filter: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter2 module_name BaseClass Unions \u00b6 Replaces rows containing types of the same variable in the data with the union of these types. Example: Configuration File: [[unifier]] name = \"unify\" kind = \"union\" Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter2 module_name SubClass 2 parameter2 module_name BaseClass After applying the filter: Category VarName TypeModule Type 2 parameter NA,NA int|str 2 parameter2 module_name,module_name SubClass|BaseClass Transformers \u00b6 To apply changes to the files / add type hints to the code, the code in the file is parsed into a CST. Modifying the CSTs is done by transformers which visit the nodes in the trees and modify these if necessary. The following transformers are used to achieve the functionality of the type hint generators: TypeHintTransformer - Updates aug-/assign, function definition & function parameter nodes by adding the traced type hints to the corresponding variables if that variable is in the trace data. If an already existing type hint exists, the node will not be changed. Used to add traced type hints to global, local variables and class members in assignments, to function parameters and function return in function definitions. RemoveAllTypeHintsTransformer - Removes type hints from annotated assign, function definition & function parameter nodes. Used by the evaluation inline generator to remove existing type hints of global, local variables and class members in assignments, to function parameters and function return in function definitions. AddImportTransformer - Transforms the CST by adding Import-From nodes to import the modules of the type hints in the trace data. Used to update the code in the files so that the modules of the added type hints are imported. MyPyHintTransformer - Uses the given CST to generate the corresponding stub CST. This is done by saving the CST code in a temporary file, generating the corresponding stub file (also as a temporary file) using mypy.stubgen and parsing the stub file's contents into the stub CST. Used by the stub file generator to generate the stub CST after adding the traced type hints to the CST. ImportUnionTransformer - Transforms the CST by adding the Import-From node to import Union from typing ( from typing import Union ) if the corresponding code contains a type hint which uses Union . Used by the stub file generator to add the missing import in the stub CST as mypy.stubgen annotates with Union , but does not add the corresponding import. Type Hint Generators \u00b6 After unifying the trace data, a type hint generator is used to generate files with. Which type hint generator is used is specified by the --gen-strat option. Type Hint Generators are instances which generate the files with traced type hints for callables and variables using the filtered trace data. As the trace data contains the filenames, The constraint of the trace data is that to each variable, only one type hint exists. InlineGenerator - Overwrites the files by adding the traced type hints inline. Does not overwrite existing type hints. Uses the TypeHintTransformer followed by the AddImportTransformer . EvaluationInlineGenerator - Overwrites the files by adding the inline type hints, and removing annotations for instances that do not have any trace data. Used to evaluate the traced type hints compared with the existing type hints . Uses the RemoveAllTypeHintsTransformer , followed by the TypeHintTransformer and AddImportTransformer . StubFileGenerator - Generates .pyi stub files of the affected files with the traced type hints. Existing type hints are kept. Uses the TypeHintTransformer followed by the AddImportTransformer , MyPyHintTransformer and ImportUnionTransformer , in that order.","title":"Annotating"},{"location":"workflow/annotating/#functionality","text":"The typegen module contains classes & functions to unify trace data and generate files with type hints. It also offers a command to execute the typegen workflow. \u03bb poetry run python main.py typegen --help Usage: main.py typegen [OPTIONS] Generate type hinted files using trace data Options: -p, --path PATH Path to project directory [required] -u, --unifiers TEXT Unifier to apply, as given by `name` in pytypes.toml under [[unifier]] -g, --gen-strat [stub|inline|eval_inline] Select a strategy for generating type hints [required] -v, --verbose INFO if not given, else DEBUG --help Show this message and exit. Example usage: \u03bb poetry run python main.py typegen \\ -p project_path -g eval_inline \\ -u mt -u dupl -u mult2 -u dupl -u first","title":"Functionality"},{"location":"workflow/annotating/#foundations-principles","text":"The project's approach to annotating is CST-based (Concrete-Syntax-Tree) transformation. A CST differs from an AST in that it keeps all formatting details, including comments, whitespace and parantheses, and is therefore a fitting choice for the project, as only minimals modifications to a repository's code should occur, i.e. annotations and decorators for tracing. In regards thereto, Python's AST module is a poor choice, as it only contains elements that are necessary for code execution, i.e. it drops extraneous newlines, changes all quote signs to single quotes, and perhaps worst of all, it removes all single-line comments. The project offers both inline and stub-based annotation generation, whose mechanics, both shared and individual, have been split into CST transformers. By reading in files that have been traced, trace data can be segmented on a per-file basis. From this per-file basis trace data, annotations (also called type hints) can be generated for each file using the aforementioned transformers, and output appropriately.","title":"Foundations &amp; Principles"},{"location":"workflow/annotating/#unification","text":"The trace data must be cleaned and appropriately unified to remove redundant data so that at most one type hint can be associated with each traced instance. To this extent, unifiers with a common interface have been implemented to cover unification needs. The unifiers are applied to the trace data in the order specified on the command line; the value given to each -u flag references a unifier by the name key given in the config file . The examples in the following section will contain \"Category\", \"FunctionName\", \"VarName\", \"TypeModule\" and \"Type\" at a minimum for brevity's sake.","title":"Unification"},{"location":"workflow/annotating/#unifiers","text":"Every unifier performs a different operation upon the trace data. These can largely be segmented into two categories, namely 'filtering' and 'reducing'. The former removes occurrences of trace data that are undesirable, and the latter groups rows and make replacements where appropriate.","title":"Unifiers"},{"location":"workflow/annotating/#filtering-unifiers","text":"","title":"Filtering Unifiers"},{"location":"workflow/annotating/#drop-duplicates","text":"While the tracer implementation may deduplicate trace data after halting, when the trace data is loaded into memory, every test that shares a call-path usually holds the same information, which is redundant, and can therefore be removed. Example: Configuration File: [[unifier]] name = \"remove_dups\" kind = \"dedup\" Trace Data: FunctionName VarName TypeModule Type test_function local_variable NA str function parameter NA int function parameter NA int After applying the filter: FunctionName VarName TypeModule Type test_function local_variable NA str function parameter NA int","title":"Drop Duplicates"},{"location":"workflow/annotating/#drop-test-functions","text":"The project always applies its decorators to test functions and methods , which leads to trace information about the test also being stored, and possibly generated during the annotation process . If the user does not want to retain this information, then this filter should be applied, which simply drops all rows that reference testing callables. Example: Configuration File: [[unifier]] name = \"ignore_test\" kind = \"drop_test\" test_name_pat = \"test_\" Trace Data: Category FunctionName VarName TypeModule Type 1 test_function local_variable NA str 2 function parameter NA int 2 function parameter NA int After applying the filter: Category FunctionName VarName TypeModule Type 2 function parameter NA int 2 function parameter NA int","title":"Drop Test Functions"},{"location":"workflow/annotating/#min-threshold","text":"Drop all rows whose types appear less often than the minimum threshold. This is a simple attempt to detect API misusage in tests; if a statistically significant amount of tests use a certain signature, and a very low amount of other tests use a different one, then this unifier will remove those rows. Example: Configuration File: [[unifier]] name = \"min_threshold\" kind = \"drop_min_threshold\" min_threshold = 0.3 Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA str After applying the filter: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA int 2 parameter NA int","title":"Min-Threshold"},{"location":"workflow/annotating/#drop-of-multiple-types","text":"Drops rows containing variables of multiple types. It can be used to drop variables which do not have any distinct type hint as they have too many different type hints. Example: Configuration File: [[unifier]] name = \"drop_explicit_3\" kind = \"drop_mult_var\" min_amount_types_to_drop = 3 Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter NA bool 2 parameter NA float 2 parameter2 NA int 2 parameter2 NA int 2 parameter2 NA str After applying the filter: Category VarName TypeModule Type 2 parameter2 NA int 2 parameter2 NA int 2 parameter2 NA str","title":"Drop of multiple types"},{"location":"workflow/annotating/#keep-only-first","text":"Keeps only the first row of each variable. It can be used to ensure that each variable in the trace data has only one type hint. Thus, it is often used as the last filter. Example: Configuration File: [[unifier]] name = \"keep_first\" kind = \"keep_only_first\" Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter2 module_name SubClass 2 parameter2 module_name BaseClass After applying the filter: Category VarName TypeModule Type 2 parameter NA int 2 parameter2 module_name SubClass","title":"Keep only first"},{"location":"workflow/annotating/#reducing-unifiers","text":"","title":"Reducing Unifiers"},{"location":"workflow/annotating/#subtypes-common-interfaces","text":"Replaces rows containing types of the same variable in the data with their earliest common base type. This unifier uses the Resolver implementation to load the MRO s for such rows in order to find the said shared base type. The instance can also be defined so that only type hints are replaced if the common base type is also in the trace data. No replacement occurs for undesirable base types, such as abc.ABC , abc.ABCMeta and object . Example: Configuration File: [[unifier]] name = \"unify_subtypes_strict\" kind = \"unify_subty\" only_unify_if_base_was_traced = true Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter2 module_name SubClass 2 parameter2 module_name BaseClass (In this example, module_name.SubClass inherits from module_name.BaseClass.) After applying the filter: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter2 module_name BaseClass","title":"Subtypes &amp; Common Interfaces"},{"location":"workflow/annotating/#unions","text":"Replaces rows containing types of the same variable in the data with the union of these types. Example: Configuration File: [[unifier]] name = \"unify\" kind = \"union\" Trace Data: Category VarName TypeModule Type 2 parameter NA int 2 parameter NA str 2 parameter2 module_name SubClass 2 parameter2 module_name BaseClass After applying the filter: Category VarName TypeModule Type 2 parameter NA,NA int|str 2 parameter2 module_name,module_name SubClass|BaseClass","title":"Unions"},{"location":"workflow/annotating/#transformers","text":"To apply changes to the files / add type hints to the code, the code in the file is parsed into a CST. Modifying the CSTs is done by transformers which visit the nodes in the trees and modify these if necessary. The following transformers are used to achieve the functionality of the type hint generators: TypeHintTransformer - Updates aug-/assign, function definition & function parameter nodes by adding the traced type hints to the corresponding variables if that variable is in the trace data. If an already existing type hint exists, the node will not be changed. Used to add traced type hints to global, local variables and class members in assignments, to function parameters and function return in function definitions. RemoveAllTypeHintsTransformer - Removes type hints from annotated assign, function definition & function parameter nodes. Used by the evaluation inline generator to remove existing type hints of global, local variables and class members in assignments, to function parameters and function return in function definitions. AddImportTransformer - Transforms the CST by adding Import-From nodes to import the modules of the type hints in the trace data. Used to update the code in the files so that the modules of the added type hints are imported. MyPyHintTransformer - Uses the given CST to generate the corresponding stub CST. This is done by saving the CST code in a temporary file, generating the corresponding stub file (also as a temporary file) using mypy.stubgen and parsing the stub file's contents into the stub CST. Used by the stub file generator to generate the stub CST after adding the traced type hints to the CST. ImportUnionTransformer - Transforms the CST by adding the Import-From node to import Union from typing ( from typing import Union ) if the corresponding code contains a type hint which uses Union . Used by the stub file generator to add the missing import in the stub CST as mypy.stubgen annotates with Union , but does not add the corresponding import.","title":"Transformers"},{"location":"workflow/annotating/#type-hint-generators","text":"After unifying the trace data, a type hint generator is used to generate files with. Which type hint generator is used is specified by the --gen-strat option. Type Hint Generators are instances which generate the files with traced type hints for callables and variables using the filtered trace data. As the trace data contains the filenames, The constraint of the trace data is that to each variable, only one type hint exists. InlineGenerator - Overwrites the files by adding the traced type hints inline. Does not overwrite existing type hints. Uses the TypeHintTransformer followed by the AddImportTransformer . EvaluationInlineGenerator - Overwrites the files by adding the inline type hints, and removing annotations for instances that do not have any trace data. Used to evaluate the traced type hints compared with the existing type hints . Uses the RemoveAllTypeHintsTransformer , followed by the TypeHintTransformer and AddImportTransformer . StubFileGenerator - Generates .pyi stub files of the affected files with the traced type hints. Existing type hints are kept. Uses the TypeHintTransformer followed by the AddImportTransformer , MyPyHintTransformer and ImportUnionTransformer , in that order.","title":"Type Hint Generators"},{"location":"workflow/evaluating/","text":"Functionality \u00b6 The evaluation module contains classes/functions to evaluate the traced type hints by using the previously existing type hints. A requirement for successful/meaningful evaluation is the usage of the evaluation inline generator when annotating the traced type hints to the files. Additionally, also contains classes/functions to evaluate the speed of the tracing compared and without tracing. \u03bb poetry run python main.py evaluate --help Usage: main.py evaluate [OPTIONS] Evaluate given original and traced repository Options: -o, --original PATH Path to original project directory [required] -t, --traced PATH Path to traced project directory [required] -s, --store PATH Path to store performance & metric data [required] -d, --data_name TEXT Name for data files --help Show this message and exit. Example usage: \u03bb poetry run python main.py evaluate \\ -o original_project_path \\ -t traced_project_path \\ -s path_to_save_evaluation_data \\ -d data_file_name Note: The command does not evaluate the repositories, it stores the data necessary for evaluation. The actual evaluation can be done by loading the data and analyzing it. The template file ipynb_evaluation_template.py in evaluation can be used as a template / base implementation for the jupyter notebook file to evaluate the data. On executing the command, the following steps are done: Foundations & Principles \u00b6 The project's approach to evaluation is to compare the repository/project before, and after annotating the type hints from tracing (will be called original repository and traced repository). The goal is find out which variables still keep the type hints, and which have different type hints after tracing. By comparing the type hints, the quality of the tracing can be measured. Additionally, potential issues of the tracing and traced type hint annotation can be identified and the project can be improved. The data about the speed of the tracing compared and without tracing can also be evaluated. For more details, see Performance Data . Typehint data \u00b6 When comparing a file before and after traced type hint annotation, the type hints have to be compared. This is done by comparing the so-called typehint data of the original and the traced file (= the original file after annotating). The typehint data contains the information about type hints of a file/multiple files. It is used to find out which variables have what kind of type hint. By comparing the typehint data of the original and traced file, it can be determined whether the type hints of the matching variables also match or differ. Column Meaning Type Null? Filename Relative path to file of traced instance from project root string Never Class Name of class traced instance is in string When not in a class' scope FunctionName Name of function traced instance is in string When not in a function's scope ColumnOffset The column offset of the line the traced instance occurs on uint Never Category Number identifying context traced instance appears in int Never VarName Name of traced instance string Never Type Name of traced instance's type string Never As the line numbers of the original and traced file due to the additional imports differ, the column offset is used instead. It corresponds to the scope of the variable. To determine the typehint data for one or more files, the FileTypeHintsCollector is used. Metric data \u00b6 The comparison of the original and traced typehint data is done by merging their rows. This is done to find out which variables in the original and traced typehint data are matching. Due to the merge, two type columns exist: The type in the original typehint data and the traced typehint data. Additionally, it is checked whether a variable which has a type hint in one file also has a type hint in the other file. The corresponding information cna be found in the Completeness column. It returns the information whether the same variable in the original and in the traced file has a type hint in both files. It is null if there is a type hint in the traced file, but not in the original. In addition to that, the Correctness Column is introduced which returns the information whether the type hints match. It is automatically False, if the corresponding completeness is False and null if the corresponding completeness is null. The merged data which the new schema is called \"metric data\". Column Meaning Type Null? Filename Relative path to file of traced instance from project root string Never Class Name of class traced instance is in string When not in a class' scope FunctionName Name of function traced instance is in string When not in a function's scope ColumnOffset The column offset of the line the traced instance occurs on uint Never Category Number identifying context traced instance appears in int Never VarName Name of traced instance string Never OriginalType Name of the type hint in the original files string When not existing in the original typehint data GeneratedType Name of the type hint in the traced files string When not existing in the traced typehint data Completeness Do OriginalType and GeneratedType exist? bool When OriginalType is null Correctness Do OriginalType and GeneratedType match? bool When OriginalType is null Apart from determining the total completeness and correctness, it can also be used to determine the completeness and correctness for each file. It can be evaluated which files have high completeness and/or high correctness or which don't. With this, the files with low completeness/low correctness can be traced and figure out the issues. Thus, improvements can be figured out to improve the quality of the tracing and traced type hint annotation . To determine the metric data given two typehint data instances, the metric data calculator is used. Performance data \u00b6 Apart from generating the trace data, the tracing can also generate the so-called performance data. This can be done by setting the benchmark_performance value to True in the configuration . It contains the execution times of the test function without tracing, with tracing without optimizations and with optimizations. Additionally, the tracing is also benchmarked by the the minimum implementation of a tracer (The TracerBase/the NoOperationTracer). It can be used to evaluate whether the tracer is faster with/without optimizations and how much slower it is compared to execution without tracing. Compared to other data schemas, the times are stored in an array ( np.ndarray ). Collecting and deserializing the performance data is done by the PerformanceDataFileCollector Trace Data File Collection & Deserialization \u00b6 The trace data files which have been generated by tracing have to be collected and deserialized into one single dataframe. This is done by using the trace data file collector . This is used to find out which files have been changed by traced type hint annotation . Original file paths and traced file paths collection \u00b6 The file paths in the trace data are iterated. Combined with the original repository & traced repository path, the original & traced file paths are determined. The corresponding files are compared. If the traced type hint annotation did not change the file, then the file contents of the original file and the file after annotation are the same. If the file contents are different, then the annotating has modified the file. The resulting original and traced file paths whose corresponding files differ are used to determine the original typehint data and the traced typehint data. Typehint data collection \u00b6 To collect the typehint data for multiple files, the FileTypeHintsCollector is used. The instance collects the typehint data for each file and returns the data as a single dataframe. This is done for the original file paths and the traced file paths, resulting in 2 typehint data instances: The original and traced typehint data. Metric data calculation \u00b6 After getting the original and traced typehint data, the metric data calculator is used to get the metric data. Saving the metric and performance data \u00b6 After getting the metric data, it is serialized in the data file path provided by the command options. Additionally, the performance data is collected and deserialized by the PerformanceDataFileCollector into one single array. The array is also serialized in the same data file path; only with a different file extension. After executing the command, the metric and performance data are stored in the data file paths. A jupyter notebook can be used to analyze the data. The template file ipynb_evaluation_template.py in evaluation can be used as a template/base implementation for the jupyter notebook file to evaluate the data. FileTypeHintsCollector \u00b6 Given a folder path/ or one or more file paths, collects the type hints in the .py files and stores these in a typehint data instance. It does this by parsing the code of each file to a CST (common syntax tree) and finding the type hints of each variable/function return.with a visitor. To ensure that matching types are stored in the typehint data with the same type name, multiple normalization algorithms are used to include the modules to the name and unify type unions. Examples: from pathlib import Path import pathlib import typing a : Path = ... # -> Collected type hint name is pathlib.Path b : pathlib . Path = ... # -> Collected type hint name is pathlib.Path c : str | int = ... # -> Collected type hint name is int | str d : typing . Union [ int , str ] = ... # -> Collected type hint name is int | str Used to get the typehint data of multiple files. Note: Using an AST would probably also work, but since CSTs have already been used in the typegen module, the same library has been used. MetricDataCalculator \u00b6 Given two typehint data instances (considered as the original and traced typehint data), calculates the corresponding metric data. Is done by merging the typehint data instances. Note: Due to using the column offsets instead of the line numbers, following conflicts can arise: Original file: e : bool = True e : str = \"str\" Traced file: e = True e : bool = \"str\" or: e : bool = True e = \"str\" The original typehint data contains two rows for the two lines in which 'e' is assigned to a value. The contents of the two rows, except for the type name, match. Compared to the original typehint data, the traced typehint data only has one row in both cases. Since the line number does not exist and the column offset is the same in both cases, the traced typehint data would be the same in both cases. Thus, it is not possible to differentiate between the two cases, resulting in the following conflict: When merging, it has to be decided whether the rows containing the information for e: bool (Type hints match) should be merged or whether e: str of the original typehint data and e: bool of the traced typehint data should be merged (type hints differ). This can affect the completeness and correctness. The metric data calculator is defined in such a way that it does the former, increasing the correctness. PerformanceDataFileCollector \u00b6 Given a folder path, collects trace data files and deserializes them into one single performance data dataframe. Bonus: Evaluation Template \u00b6 Not part of the API as it is considered a jupyter notebook file. To load the template .py file in jupyter notebook, install the jupytext module. Loads the metric & performance data and determines the total completeness and correctness. Also determines which files have a high/low completeness/correctness. Additionally, analyzes the performance data by plotting the execution times with tracing compared to times without tracing as scatter points. Can be used as a template/base implementation for evaluating the metric & performance data.","title":"Evaluating"},{"location":"workflow/evaluating/#functionality","text":"The evaluation module contains classes/functions to evaluate the traced type hints by using the previously existing type hints. A requirement for successful/meaningful evaluation is the usage of the evaluation inline generator when annotating the traced type hints to the files. Additionally, also contains classes/functions to evaluate the speed of the tracing compared and without tracing. \u03bb poetry run python main.py evaluate --help Usage: main.py evaluate [OPTIONS] Evaluate given original and traced repository Options: -o, --original PATH Path to original project directory [required] -t, --traced PATH Path to traced project directory [required] -s, --store PATH Path to store performance & metric data [required] -d, --data_name TEXT Name for data files --help Show this message and exit. Example usage: \u03bb poetry run python main.py evaluate \\ -o original_project_path \\ -t traced_project_path \\ -s path_to_save_evaluation_data \\ -d data_file_name Note: The command does not evaluate the repositories, it stores the data necessary for evaluation. The actual evaluation can be done by loading the data and analyzing it. The template file ipynb_evaluation_template.py in evaluation can be used as a template / base implementation for the jupyter notebook file to evaluate the data. On executing the command, the following steps are done:","title":"Functionality"},{"location":"workflow/evaluating/#foundations-principles","text":"The project's approach to evaluation is to compare the repository/project before, and after annotating the type hints from tracing (will be called original repository and traced repository). The goal is find out which variables still keep the type hints, and which have different type hints after tracing. By comparing the type hints, the quality of the tracing can be measured. Additionally, potential issues of the tracing and traced type hint annotation can be identified and the project can be improved. The data about the speed of the tracing compared and without tracing can also be evaluated. For more details, see Performance Data .","title":"Foundations &amp; Principles"},{"location":"workflow/evaluating/#typehint-data","text":"When comparing a file before and after traced type hint annotation, the type hints have to be compared. This is done by comparing the so-called typehint data of the original and the traced file (= the original file after annotating). The typehint data contains the information about type hints of a file/multiple files. It is used to find out which variables have what kind of type hint. By comparing the typehint data of the original and traced file, it can be determined whether the type hints of the matching variables also match or differ. Column Meaning Type Null? Filename Relative path to file of traced instance from project root string Never Class Name of class traced instance is in string When not in a class' scope FunctionName Name of function traced instance is in string When not in a function's scope ColumnOffset The column offset of the line the traced instance occurs on uint Never Category Number identifying context traced instance appears in int Never VarName Name of traced instance string Never Type Name of traced instance's type string Never As the line numbers of the original and traced file due to the additional imports differ, the column offset is used instead. It corresponds to the scope of the variable. To determine the typehint data for one or more files, the FileTypeHintsCollector is used.","title":"Typehint data"},{"location":"workflow/evaluating/#metric-data","text":"The comparison of the original and traced typehint data is done by merging their rows. This is done to find out which variables in the original and traced typehint data are matching. Due to the merge, two type columns exist: The type in the original typehint data and the traced typehint data. Additionally, it is checked whether a variable which has a type hint in one file also has a type hint in the other file. The corresponding information cna be found in the Completeness column. It returns the information whether the same variable in the original and in the traced file has a type hint in both files. It is null if there is a type hint in the traced file, but not in the original. In addition to that, the Correctness Column is introduced which returns the information whether the type hints match. It is automatically False, if the corresponding completeness is False and null if the corresponding completeness is null. The merged data which the new schema is called \"metric data\". Column Meaning Type Null? Filename Relative path to file of traced instance from project root string Never Class Name of class traced instance is in string When not in a class' scope FunctionName Name of function traced instance is in string When not in a function's scope ColumnOffset The column offset of the line the traced instance occurs on uint Never Category Number identifying context traced instance appears in int Never VarName Name of traced instance string Never OriginalType Name of the type hint in the original files string When not existing in the original typehint data GeneratedType Name of the type hint in the traced files string When not existing in the traced typehint data Completeness Do OriginalType and GeneratedType exist? bool When OriginalType is null Correctness Do OriginalType and GeneratedType match? bool When OriginalType is null Apart from determining the total completeness and correctness, it can also be used to determine the completeness and correctness for each file. It can be evaluated which files have high completeness and/or high correctness or which don't. With this, the files with low completeness/low correctness can be traced and figure out the issues. Thus, improvements can be figured out to improve the quality of the tracing and traced type hint annotation . To determine the metric data given two typehint data instances, the metric data calculator is used.","title":"Metric data"},{"location":"workflow/evaluating/#performance-data","text":"Apart from generating the trace data, the tracing can also generate the so-called performance data. This can be done by setting the benchmark_performance value to True in the configuration . It contains the execution times of the test function without tracing, with tracing without optimizations and with optimizations. Additionally, the tracing is also benchmarked by the the minimum implementation of a tracer (The TracerBase/the NoOperationTracer). It can be used to evaluate whether the tracer is faster with/without optimizations and how much slower it is compared to execution without tracing. Compared to other data schemas, the times are stored in an array ( np.ndarray ). Collecting and deserializing the performance data is done by the PerformanceDataFileCollector","title":"Performance data"},{"location":"workflow/evaluating/#trace-data-file-collection-deserialization","text":"The trace data files which have been generated by tracing have to be collected and deserialized into one single dataframe. This is done by using the trace data file collector . This is used to find out which files have been changed by traced type hint annotation .","title":"Trace Data File Collection &amp; Deserialization"},{"location":"workflow/evaluating/#original-file-paths-and-traced-file-paths-collection","text":"The file paths in the trace data are iterated. Combined with the original repository & traced repository path, the original & traced file paths are determined. The corresponding files are compared. If the traced type hint annotation did not change the file, then the file contents of the original file and the file after annotation are the same. If the file contents are different, then the annotating has modified the file. The resulting original and traced file paths whose corresponding files differ are used to determine the original typehint data and the traced typehint data.","title":"Original file paths and traced file paths collection"},{"location":"workflow/evaluating/#typehint-data-collection","text":"To collect the typehint data for multiple files, the FileTypeHintsCollector is used. The instance collects the typehint data for each file and returns the data as a single dataframe. This is done for the original file paths and the traced file paths, resulting in 2 typehint data instances: The original and traced typehint data.","title":"Typehint data collection"},{"location":"workflow/evaluating/#metric-data-calculation","text":"After getting the original and traced typehint data, the metric data calculator is used to get the metric data.","title":"Metric data calculation"},{"location":"workflow/evaluating/#saving-the-metric-and-performance-data","text":"After getting the metric data, it is serialized in the data file path provided by the command options. Additionally, the performance data is collected and deserialized by the PerformanceDataFileCollector into one single array. The array is also serialized in the same data file path; only with a different file extension. After executing the command, the metric and performance data are stored in the data file paths. A jupyter notebook can be used to analyze the data. The template file ipynb_evaluation_template.py in evaluation can be used as a template/base implementation for the jupyter notebook file to evaluate the data.","title":"Saving the metric and performance data"},{"location":"workflow/evaluating/#filetypehintscollector","text":"Given a folder path/ or one or more file paths, collects the type hints in the .py files and stores these in a typehint data instance. It does this by parsing the code of each file to a CST (common syntax tree) and finding the type hints of each variable/function return.with a visitor. To ensure that matching types are stored in the typehint data with the same type name, multiple normalization algorithms are used to include the modules to the name and unify type unions. Examples: from pathlib import Path import pathlib import typing a : Path = ... # -> Collected type hint name is pathlib.Path b : pathlib . Path = ... # -> Collected type hint name is pathlib.Path c : str | int = ... # -> Collected type hint name is int | str d : typing . Union [ int , str ] = ... # -> Collected type hint name is int | str Used to get the typehint data of multiple files. Note: Using an AST would probably also work, but since CSTs have already been used in the typegen module, the same library has been used.","title":"FileTypeHintsCollector"},{"location":"workflow/evaluating/#metricdatacalculator","text":"Given two typehint data instances (considered as the original and traced typehint data), calculates the corresponding metric data. Is done by merging the typehint data instances. Note: Due to using the column offsets instead of the line numbers, following conflicts can arise: Original file: e : bool = True e : str = \"str\" Traced file: e = True e : bool = \"str\" or: e : bool = True e = \"str\" The original typehint data contains two rows for the two lines in which 'e' is assigned to a value. The contents of the two rows, except for the type name, match. Compared to the original typehint data, the traced typehint data only has one row in both cases. Since the line number does not exist and the column offset is the same in both cases, the traced typehint data would be the same in both cases. Thus, it is not possible to differentiate between the two cases, resulting in the following conflict: When merging, it has to be decided whether the rows containing the information for e: bool (Type hints match) should be merged or whether e: str of the original typehint data and e: bool of the traced typehint data should be merged (type hints differ). This can affect the completeness and correctness. The metric data calculator is defined in such a way that it does the former, increasing the correctness.","title":"MetricDataCalculator"},{"location":"workflow/evaluating/#performancedatafilecollector","text":"Given a folder path, collects trace data files and deserializes them into one single performance data dataframe.","title":"PerformanceDataFileCollector"},{"location":"workflow/evaluating/#bonus-evaluation-template","text":"Not part of the API as it is considered a jupyter notebook file. To load the template .py file in jupyter notebook, install the jupytext module. Loads the metric & performance data and determines the total completeness and correctness. Also determines which files have a high/low completeness/correctness. Additionally, analyzes the performance data by plotting the execution times with tracing compared to times without tracing as scatter points. Can be used as a template/base implementation for evaluating the metric & performance data.","title":"Bonus: Evaluation Template"},{"location":"workflow/fetching/","text":"Functionality \u00b6 The fetching module contains classes that facilitate the process of taking a repository and applying decorators for the functions that need tracing behind a user-friendly API. It also offers a command to execute this part of the workflow: \u03bb poetry run python main.py fetch --help Usage: main.py fetch [OPTIONS] download repositories and apply tracing decorators Options: -u, --url TEXT URL to a repository [required] -o, --output PATH Download output path [required] -f, --format [Git|Archive|Local] Indicate repository format explicitly -n, --no-traverse Do not go down the directory tree of the tests, instead stay in the first level -e, --eval Instead of generating one copy, generate two copies: The original & the repository for tracing -v, --verbose INFO if not given, else CRITICAL --help Show this message and exit. Example usage: \u03bb poetry run python main.py fetch \\ --url pytest \\ --output pytest-typed \u03bb python run python main.py fetch \\ --url \"git@github.com:nvbn/thefuck.git\" \\ --output thefuck --eval Foundations & Principles \u00b6 Modify given codebase by detecting test folders and applying decorator for tracing to test functions Supported Formats \u00b6 Git repository Local folder Archives Decorator Application \u00b6 This is further documented here .","title":"Fetching"},{"location":"workflow/fetching/#functionality","text":"The fetching module contains classes that facilitate the process of taking a repository and applying decorators for the functions that need tracing behind a user-friendly API. It also offers a command to execute this part of the workflow: \u03bb poetry run python main.py fetch --help Usage: main.py fetch [OPTIONS] download repositories and apply tracing decorators Options: -u, --url TEXT URL to a repository [required] -o, --output PATH Download output path [required] -f, --format [Git|Archive|Local] Indicate repository format explicitly -n, --no-traverse Do not go down the directory tree of the tests, instead stay in the first level -e, --eval Instead of generating one copy, generate two copies: The original & the repository for tracing -v, --verbose INFO if not given, else CRITICAL --help Show this message and exit. Example usage: \u03bb poetry run python main.py fetch \\ --url pytest \\ --output pytest-typed \u03bb python run python main.py fetch \\ --url \"git@github.com:nvbn/thefuck.git\" \\ --output thefuck --eval","title":"Functionality"},{"location":"workflow/fetching/#foundations-principles","text":"Modify given codebase by detecting test folders and applying decorator for tracing to test functions","title":"Foundations &amp; Principles"},{"location":"workflow/fetching/#supported-formats","text":"Git repository Local folder Archives","title":"Supported Formats"},{"location":"workflow/fetching/#decorator-application","text":"This is further documented here .","title":"Decorator Application"},{"location":"workflow/tracing/","text":"Functionality \u00b6 The tracing module contains classes that facilitate the tracing process behind a user-friendly API. Note that it does not offer a command for performing the tracing procedure, which should instead be done by executing the decorated tests of the project . The testing process can be highly customised on a per-project basis, and as such represents a high-effort low-reward coding investment on this project's end. Foundations & Principles \u00b6 sys.settrace \u00b6 sys.settrace is a Python function that allows a callable to be set that is invoked on every line of Python code that comes after it. This registered callable, henceforth refered to as the trace function is expected to have three arguments: frame : a representation of the current stack frame, containing references to further execution-related objects, such as: the previous frame visible globals variables that have been placed on the stack and more event : a string indicating the manner in which the current line of Python is handled. Relevant for us are: call: a callable was entered line: plain line of code that is about to be executed (NOTE: this means the line will executed in the next interpreter step, not when it is encountered by the trace function) return: a callable is about to return arg : a value that differs depending on the given event. Relevant for us are: call: arg is None. Retrieving the values of arguments is to be performed separately. line: arg is None. Retrieving the values of variables on this line is also to be performed separately. return: arg is the value that will be returned from the callable. Effect on Coverage, Debugging and other trace-related Tooling \u00b6 While this approach is very powerful, it comes at a detriment to the development process. pdb , which is the Python debugger, uses the sys.settrace API to provide information during debugging sesesions. Similarly, the coverage tool, which provides code-coverage information of Python programs, also uses this entrypoint. sys.settrace only allows for one trace function to be set, meaning no tooling that also uses this API can coexist with another. Therefore, along a codepath that uses the entrypoint in question, determining code coverage, or attempting to debug, is simply not possible. API \u00b6 The project implements the required functionalities in the tracing module, in the classes of Tracer and TraceBatchUpdate , which trace and collect instances into a DataFrame by the following schema: Column Meaning Type Null? Filename Relative path to file of traced instance from project root string Never ClassModule Module of class traced instance is in string When not in a class' scope Class Name of class traced instance is in string When not in a class' scope FunctionName Name of function traced instance is in string When not in a function's scope LineNo Line number traced instance occurs on uint Never Category Number identifying context traced instance appears in int Never VarName Name of traced instance string Never TypeModule Module of traced instance's type string When the type is builtin Type Name of traced instance's type string Never Category can take on 5 different values, which are contained in the TraceDataCategory enum class: LOCAL_VARIABLE , GLOBAL_VARIABLE , CLASS_MEMBER , FUNCTION_PARAMETER and FUNCTION_RETURN . @decorators.trace - Minimally Intrusive Tracing API \u00b6 The fetching process generates instances of this decorator function where applicable. Each invocation parses the config file from the root of the project, and executes the tracing process on the marked callable. This decorator takes care to forward all arguments that pytest may inject into the decorated function so that all kinds of monkeypatching , fixtures and much else. After tracing has concluded, the accumulated DataFrame in the Tracer is serialised under pytypes/{project}/{test_case}/{func_name}-{hash(df)}.pytype . The hashing is performed to force tests that are executed in loops (e.g. by @pytest.mark.parametrize ) to not overwrite their predecessor's data, which could cause valuable information that would indicate union types, to be lost. If the traced test causes an uncaught exception, then a similarly named file with an .err suffix is generated containing the traceback. Additionally, if the benchmark_performance value has been set to true in pytypes.toml , then additional tracing will be performed that does not store any trace data, and again with logging enabled but with optimisations turned off. The runtimes for each execution are serialised next to the logged trace files. Tracer - Setting sys.settrace and Collecting Data \u00b6 The events generated by the trace function are caught in the Tracer class' _on_trace_is_called method after its start_trace method has been called. This ends when its end_trace method being called. This functionality has again been wrapped in its active_trace method, which can be used in Python's with statements. These methods are called from the @decorators.trace function, as documented in the previous section . The implementation backs-up any previously set trace function by reading from sys.gettrace , and sets its own using sys.settrace . This newly set trace function handles the call , line and return events, and ignores the exception and opcode events, as no relevant data can be gleamed from these. Each event is handled in its own appropriately named method, and the tracer combines the DataFrame s generated by BatchTraceUpdate . When tracing is halted, the DataFrame is deduplicated to remove redundant information and the old trace function is restored. During tracing, the values for TypeModule and Type are derived from the type function, which is passed to the Resolver to mirror components to Python's from x.y import z import style. BatchTraceUpdate - Simplifying and Batching Trace Updates \u00b6 Despite the events emitted by sys.settrace being disjunct, the operations that must be performed on the basis thereof are not. For example, the handling of the return event is a superset of that of the line event. Furthermore, the line event must perform update operations for both local and global variables. Also, the general functionality necessary to update the DataFrame is repetitive, especially with FileName , ClassModule , Class and FunctionName being identical for every trace call within the same function. The BatchTraceUpdate class was designed to solve these issues; the aforementioned repetitive data is passed to the constructor, to be reused in its methods. These methods form a builder-pattern style interface for each relevant category, allowing updates to be chained as each event requires. After all updates have been handled, a DataFrame can be produced that is to added to the otherwise accumulated trace data.","title":"Tracing"},{"location":"workflow/tracing/#functionality","text":"The tracing module contains classes that facilitate the tracing process behind a user-friendly API. Note that it does not offer a command for performing the tracing procedure, which should instead be done by executing the decorated tests of the project . The testing process can be highly customised on a per-project basis, and as such represents a high-effort low-reward coding investment on this project's end.","title":"Functionality"},{"location":"workflow/tracing/#foundations-principles","text":"","title":"Foundations &amp; Principles"},{"location":"workflow/tracing/#syssettrace","text":"sys.settrace is a Python function that allows a callable to be set that is invoked on every line of Python code that comes after it. This registered callable, henceforth refered to as the trace function is expected to have three arguments: frame : a representation of the current stack frame, containing references to further execution-related objects, such as: the previous frame visible globals variables that have been placed on the stack and more event : a string indicating the manner in which the current line of Python is handled. Relevant for us are: call: a callable was entered line: plain line of code that is about to be executed (NOTE: this means the line will executed in the next interpreter step, not when it is encountered by the trace function) return: a callable is about to return arg : a value that differs depending on the given event. Relevant for us are: call: arg is None. Retrieving the values of arguments is to be performed separately. line: arg is None. Retrieving the values of variables on this line is also to be performed separately. return: arg is the value that will be returned from the callable.","title":"sys.settrace"},{"location":"workflow/tracing/#effect-on-coverage-debugging-and-other-trace-related-tooling","text":"While this approach is very powerful, it comes at a detriment to the development process. pdb , which is the Python debugger, uses the sys.settrace API to provide information during debugging sesesions. Similarly, the coverage tool, which provides code-coverage information of Python programs, also uses this entrypoint. sys.settrace only allows for one trace function to be set, meaning no tooling that also uses this API can coexist with another. Therefore, along a codepath that uses the entrypoint in question, determining code coverage, or attempting to debug, is simply not possible.","title":"Effect on Coverage, Debugging and other trace-related Tooling"},{"location":"workflow/tracing/#api","text":"The project implements the required functionalities in the tracing module, in the classes of Tracer and TraceBatchUpdate , which trace and collect instances into a DataFrame by the following schema: Column Meaning Type Null? Filename Relative path to file of traced instance from project root string Never ClassModule Module of class traced instance is in string When not in a class' scope Class Name of class traced instance is in string When not in a class' scope FunctionName Name of function traced instance is in string When not in a function's scope LineNo Line number traced instance occurs on uint Never Category Number identifying context traced instance appears in int Never VarName Name of traced instance string Never TypeModule Module of traced instance's type string When the type is builtin Type Name of traced instance's type string Never Category can take on 5 different values, which are contained in the TraceDataCategory enum class: LOCAL_VARIABLE , GLOBAL_VARIABLE , CLASS_MEMBER , FUNCTION_PARAMETER and FUNCTION_RETURN .","title":"API"},{"location":"workflow/tracing/#decoratorstrace-minimally-intrusive-tracing-api","text":"The fetching process generates instances of this decorator function where applicable. Each invocation parses the config file from the root of the project, and executes the tracing process on the marked callable. This decorator takes care to forward all arguments that pytest may inject into the decorated function so that all kinds of monkeypatching , fixtures and much else. After tracing has concluded, the accumulated DataFrame in the Tracer is serialised under pytypes/{project}/{test_case}/{func_name}-{hash(df)}.pytype . The hashing is performed to force tests that are executed in loops (e.g. by @pytest.mark.parametrize ) to not overwrite their predecessor's data, which could cause valuable information that would indicate union types, to be lost. If the traced test causes an uncaught exception, then a similarly named file with an .err suffix is generated containing the traceback. Additionally, if the benchmark_performance value has been set to true in pytypes.toml , then additional tracing will be performed that does not store any trace data, and again with logging enabled but with optimisations turned off. The runtimes for each execution are serialised next to the logged trace files.","title":"@decorators.trace - Minimally Intrusive Tracing API"},{"location":"workflow/tracing/#tracer-setting-syssettrace-and-collecting-data","text":"The events generated by the trace function are caught in the Tracer class' _on_trace_is_called method after its start_trace method has been called. This ends when its end_trace method being called. This functionality has again been wrapped in its active_trace method, which can be used in Python's with statements. These methods are called from the @decorators.trace function, as documented in the previous section . The implementation backs-up any previously set trace function by reading from sys.gettrace , and sets its own using sys.settrace . This newly set trace function handles the call , line and return events, and ignores the exception and opcode events, as no relevant data can be gleamed from these. Each event is handled in its own appropriately named method, and the tracer combines the DataFrame s generated by BatchTraceUpdate . When tracing is halted, the DataFrame is deduplicated to remove redundant information and the old trace function is restored. During tracing, the values for TypeModule and Type are derived from the type function, which is passed to the Resolver to mirror components to Python's from x.y import z import style.","title":"Tracer - Setting sys.settrace and Collecting Data"},{"location":"workflow/tracing/#batchtraceupdate-simplifying-and-batching-trace-updates","text":"Despite the events emitted by sys.settrace being disjunct, the operations that must be performed on the basis thereof are not. For example, the handling of the return event is a superset of that of the line event. Furthermore, the line event must perform update operations for both local and global variables. Also, the general functionality necessary to update the DataFrame is repetitive, especially with FileName , ClassModule , Class and FunctionName being identical for every trace call within the same function. The BatchTraceUpdate class was designed to solve these issues; the aforementioned repetitive data is passed to the constructor, to be reused in its methods. These methods form a builder-pattern style interface for each relevant category, allowing updates to be chained as each event requires. After all updates have been handled, a DataFrame can be produced that is to added to the otherwise accumulated trace data.","title":"BatchTraceUpdate - Simplifying and Batching Trace Updates"}]}